{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this project is about applying nlp techniques to understand if a given tweet is about a real disaster or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7603</th>\n",
       "      <td>10862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Officials say a quarantine is in place at an A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7604</th>\n",
       "      <td>10863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#WorldNews Fallen powerlines on G:link tram: U...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7605</th>\n",
       "      <td>10864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>on the flip side I'm at Walmart and there is a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7606</th>\n",
       "      <td>10866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Suicide bomber kills 15 in Saudi security site...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7607</th>\n",
       "      <td>10867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#stormchase Violent Record Breaking EF-5 El Re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7608 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7603  10862     NaN      NaN   \n",
       "7604  10863     NaN      NaN   \n",
       "7605  10864     NaN      NaN   \n",
       "7606  10866     NaN      NaN   \n",
       "7607  10867     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1                Forest fire near La Ronge Sask. Canada       1  \n",
       "2     All residents asked to 'shelter in place' are ...       1  \n",
       "3     13,000 people receive #wildfires evacuation or...       1  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7603  Officials say a quarantine is in place at an A...       1  \n",
       "7604  #WorldNews Fallen powerlines on G:link tram: U...       1  \n",
       "7605  on the flip side I'm at Walmart and there is a...       1  \n",
       "7606  Suicide bomber kills 15 in Saudi security site...       1  \n",
       "7607  #stormchase Violent Record Breaking EF-5 El Re...       1  \n",
       "\n",
       "[7608 rows x 5 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "train = pd.read_csv('Data/train.csv')\n",
    "test = pd.read_csv('Data/test.csv')\n",
    "\n",
    "# check the data\n",
    "train.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id             0\n",
      "keyword       61\n",
      "location    2533\n",
      "text           0\n",
      "target         0\n",
      "dtype: int64\n",
      "id             0\n",
      "keyword       26\n",
      "location    1105\n",
      "text           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check for missing values\n",
    "print(train.isnull().sum())\n",
    "\n",
    "print(test.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique values in keyword and location columns \n",
    "train.keyword.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3341"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.location.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in training data\n",
    "train['location'] = train['location'].fillna('Unknown')\n",
    "train['keyword'] = train['keyword'].fillna('None')\n",
    "\n",
    "# Fill missing values in test data\n",
    "test['location'] = test['location'].fillna('Unknown')\n",
    "test['keyword'] = test['keyword'].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine text columns for vectorization\n",
    "train['text_combined'] = train['keyword'] + ' ' + train['location'] + ' ' + train['text']\n",
    "test['text_combined'] = test['keyword'] + ' ' + test['location'] + ' ' + test['text']\n",
    "\n",
    "# Vectorize text data using Bag of Words\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# vectorizer = CountVectorizer(max_features=10000)\n",
    "\n",
    "# Vectorize text data using Tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "\n",
    "X_train = vectorizer.fit_transform(train['text_combined'])\n",
    "X_test = vectorizer.transform(test['text_combined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: Pipeline(steps=[('clf', SVC(C=1, kernel='linear'))])\n",
      "Best Parameters: {'clf': SVC(), 'clf__C': 1, 'clf__kernel': 'linear'}\n",
      "Best F1 Score: 0.7541665322785917\n",
      "Validation F1 Score: 0.7627677100494233\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Assuming X_train_split, X_val, y_train_split, y_val are already defined\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "\t('clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = [\n",
    "\t{\n",
    "\t\t'clf': [LogisticRegression()],\n",
    "\t\t'clf__C': [0.1, 1, 10]\n",
    "\t},\n",
    "\t{\n",
    "\t\t'clf': [RandomForestClassifier()],\n",
    "\t\t'clf__n_estimators': [50, 100, 200],\n",
    "\t\t'clf__max_depth': [None, 10, 20]\n",
    "\t},\n",
    "\t{\n",
    "\t\t'clf': [MultinomialNB()],\n",
    "\t\t'clf__alpha': [0.01, 0.1, 1]\n",
    "\t},\n",
    "\t{\n",
    "\t\t'clf': [XGBClassifier()],\n",
    "\t\t'clf__n_estimators': [50, 100, 200],\n",
    "\t\t'clf__max_depth': [3, 6, 9],\n",
    "\t\t'clf__learning_rate': [0.01, 0.1, 0.2]\n",
    "\t},\n",
    "\t{\n",
    "\t\t'clf': [SVC()],\n",
    "\t\t'clf__C': [0.1, 1, 10],\n",
    "\t\t'clf__kernel': ['linear', 'rbf']\n",
    "\t}\n",
    "]\n",
    "\n",
    "# Perform Grid Search CV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1')\n",
    "grid_search.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Best model and parameters\n",
    "print(\"Best Model:\", grid_search.best_estimator_)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best F1 Score:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "best_model = grid_search.best_estimator_\n",
    "val_predictions = best_model.predict(X_val)\n",
    "from sklearn.metrics import f1_score\n",
    "val_f1_score = f1_score(y_val, val_predictions)\n",
    "print(\"Validation F1 Score:\", val_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84       874\n",
      "           1       0.82      0.71      0.76       649\n",
      "\n",
      "    accuracy                           0.81      1523\n",
      "   macro avg       0.81      0.80      0.80      1523\n",
      "weighted avg       0.81      0.81      0.81      1523\n",
      "\n",
      "Accuracy: 0.8108995403808273\n",
      "F1 Score: 0.7627677100494233\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"F1 Score:\", f1_score(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "y_test_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a submission file\n",
    "submission = pd.DataFrame({'id': test['id'], 'target': y_test_pred})\n",
    "submission.to_csv('Data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
